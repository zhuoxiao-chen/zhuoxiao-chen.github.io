<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Zhuoxiao (Ivan) Chen's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="baidu-site-verification" content="code-icRL3fjRSM" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Mr Chen is currently a research assistant at The University of Queensland.">
  <meta name="keywords" content="Zhuoxiao Chen, 陈卓潇, Ivan Chen, Zhuoxiao (Ivan) Chen, Zhuoxiao, Chen, Deep Learning, Domain Adaptation, UQ, University of Queensland, The University of Queensland, Computer, Vision">
  <meta name="author" content="Zhuoxiao Chen" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: Open Sans,serif; }
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: Palatino,Palatino Linotype,Palatino LT STD,Book Antiqua,Georgia,serif; ;}
  </style>

  <link rel="icon" type="image/x-icon" href="images/uq-icon.ico">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:100%">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:200px" id="mySidebar">

  <img style="width: 90%;margin-left: 5%; padding-top: 8px; max-width: 260px" alt="UQ-LOGO" src="images/UQ-Logo-2.png">
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#education" class="w3-bar-item w3-button">Education</a>
    <a href="#experience" class="w3-bar-item w3-button">Experience</a>
    <!-- <a href="#talks" class="w3-bar-item w3-button">Talks</a> -->
    <a href="#publications" class="w3-bar-item w3-button">Publication</a>
    <!-- <a href="#service" class="w3-bar-item w3-button">Services</a> -->
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
    <a href="https://github.com/zhuoxiao-chen/paper-notes" class="w3-bar-item w3-button">Paper Notes</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <img style="width: 90%;margin-left: 5%; padding-top: 8px; max-width: 200px" alt="UQ-LOGO" src="images/UQ-Logo-2.png">
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:200px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home" 
         style="display: flex;align-items: center;justify-content: center;flex-wrap: wrap;flex-direction: row;align-content: center;">
      <img style="width: 25%;min-width: 200px;max-width: 240px; border-radius: 10px;" src="images/ivan.jpg">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
      <div style="padding: 0 3%;">
      <div style="
    display: flex;
    justify-content: center;
    flex-direction: row;
    flex-wrap: wrap;
    align-content: center;"><h1>Zhuoxiao (Ivan) Chen</h1> <h3>[陈卓潇]</h3></div>
      
      <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px">
          Ivan Chen is a Doctor of Philosophy (Ph.D) student in the 
          <a href="https://itee.uq.edu.au/">School of Information Technology and Electrical Engineering (ITEE)</a>
          at <a href="https://www.uq.edu.au/">The University of Queensland (UQ)</a>, Australia. He is also a part time 
          research assistant (RA), teaching assistant (TA) tutor and learning designer at UQ.
          His research focuses on 3D scene understanding under the supervision of 
          <a href=https://staff.itee.uq.edu.au/huang/> Prof Helen Huang</a>,  
          <a href=https://sites.google.com/view/yadanluo/home> Dr Yadan Luo</a>, 
          and <a href=https://researchers.uq.edu.au/researcher/23393> Dr Mahsa Baktashmotlagh</a>. 
          He received his Bachelor of Computer Science (Honours) degree with First Class Honours from ITEE, UQ in 2021.
        </p>
        Email: zhuoxiao [dot] chen [at] uq [dot] edu [dot] au
        <p class="w3-center">
          <a href="https://scholar.google.com/citations?user=t3cg17IAAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href=" https://github.com/zhuoxiao-chen">GitHub</a> &nbsp/&nbsp
          <a href="https://dblp.org/pid/301/7822.html"> DBLP </a>
        </p>
        </tbody></table>
        </div>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
    
    <p><li> 02/2022, Ivan is now a teaching assistant (TA) tutor for postgraduate courses at UQ
<!--     <p><li> 12/2021, Ivan received and accepted the unconditional offer of Doctor of Philosophy (PhD) of UQ -->
    <p><li> 12/2021, Ivan is selected as the <a href="https://my.uq.edu.au/graduation/graduation-speeches">Valedictorian</a> to present a speech in the graduation ceremony of the Faculty of 
Engineering, Architecture and Information Technology</li></p>
<!--     <p><li> 12/2021, Ivan has graduated from Bachelor of Computer Science (Honours) degree with the First Class Honours</li></p> -->
    <p><li> 10/2021, two papers has been accepted by <a href="https://www.acmmmasia.org/">ACM MMAsia</a></li></p>
  
<!--       <p><li> 05/2021, one paper has been accepted by <a href="https://icml.cc/">ICML 2021</a>.</li></p>
      <p><li> 05/2021, I have been selected as a Senior Area Chair for <a href="http://valser.org/">VALSE 2021</a>.</li></p>
      <p><li> 03/2021, I accepted the invitation to serve as an Area Chair for <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</li></p>
      <p><li> 03/2021, nine papers have been accepted by <a href="http://cvpr2021.theRcvf.com/">CVPR 2021</a>.</li></p>
      <p><li> 01/2021, I will give a talk about AdderNet at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>.</li></p>
      <p><li> 12/2020, two papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</li></p>
      <p><li> 11/2020, I accepted the invitation to serve as an Area Chair for <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</li></p>
      <p><li> 09/2020, six papers have been accepted by <a href="https://nips.cc/Conferences/2020">NeurIPS 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="https://eccv2020.eu/accepted-papers/">ECCV 2020</a>.</li></p> -->
      
      <!--
      <p><li> 06/2020, two papers have been accepted by <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.</li></p>
      <p><li> 07/2020, one paper has been accepted by <a href="http://2020.acmmm.org/accepted-paper-id-list.txt">ACM MM 2020</a>.</li></p>
      <p><li> 02/2020, seven papers have been accepted by <a href="http://openaccess.thecvf.com/menu.py">CVPR 2020</a>.</li></p>
      <p><li> 01/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</li></p>
      <p><li> 11/2019, three papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf">AAAI 2020</a>.</li></p>
      -->

  </div>




<!-- The News Section -->
  <div class="w3-container w3-padding-32" id="education">
   <h2>Education</h2>
    <p><li> 01/2022 - 12/2025, <strong>Doctor of Philosophy (PhD) </strong>, The University of Queensland
    <p><li> 02/2021 - 12/2021, <strong>Bachelor of Computer Science (First Class Honours) </strong>, The University of Queensland, <em><strong>GPA: 7 out of 7</strong> (Rank 1st among the graduates of the same degree in Dec 2021)</em> </li></p>
    <p><li> 02/2018 - 12/2020, <strong>Bachelor of Computer Science</strong>, The University of Queensland, <em><strong>GPA: 6.75 out of 7</strong> (Rank 1st among the graduates of the same degree in Dec 2020) </em></li></p>


</div>




<!-- The Experience Section -->
  <div class="w3-container w3-light-grey  w3-padding-32" id="experience">
    <h2>Experience</h2>
    <p><li> 12/2021 - now, <strong>Teaching Assistant (TA) Tutor</strong> for master thesis <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DATA7901">Data Science Capstone Project (DATA7901)</a> and  <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DATA7902">Data Science Capstone Project (DATA7902)</a>at UQ</li></p>
    <p><li> 12/2021 - now, <strong>Teaching Assistant (TA) Tutor</strong> for postgraduate level course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=INFS4205">INFS7205 Advanced Techniques for High Dimensional Data</a> at UQ</li></p>
    <p><li> 12/2021 - now, <strong>Learning Designer</strong> for 2nd year university computer science courses at UQ</li></p>
    <p><li> 07/2021 - now, <strong>Research Assistant (RA) </strong> at ITEE, UQ</li></p>
    <p><li> 08/2021 - 09/2021, <strong>Software Engineer</strong> for collaborative project (ITEE, UQ and <a href="https://www.logan.qld.gov.au/">Logon City Council, Australia</a>) on intelligent platform for automated road defect detection and asset management [ <a style="color: #447ec9" href="https://arxiv.org/abs/2109.00522">project</a> ]</li></p> 
    <p><li> 06/2021 - 07/2021, <strong>Winter Research Scholar</strong> of <a href="https://scholarships.uq.edu.au/scholarship/winter-research-program">Winter Research Program</a> at UQ</li></p>
    <p><li> 03/2021, <strong>Web Developer </strong> for <a href="https://mmasia2021.uqcloud.net/"> ACM Multimedia Asia 2021 Official Website </a> </li></p>
    <p><li> 07/2020 - 11/2020, <strong>Team Leader</strong> of software development team - Dodo Lab in course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DECO3801">deco3801</a> at UQ. The developed product is CovidStopper
    	[ <a style="color: #447ec9" href="https://drive.google.com/file/d/1OIK1LD6SeN1Td5xjFoqbifmPVMy6L7Ie/view?usp=sharing">commercial end</a> ][
    	<a style="color: #447ec9" href="https://drive.google.com/file/d/1Wx4ZQ3okz9F56wITXvNiyPvjty1teB0r/view?usp=sharing">general end</a> ][
    	<a style="color: #447ec9" href="https://drive.google.com/file/d/1QxxJUis61TRrZKBzAJ10uvrCgr1lPt-z/view?usp=sharing">lab staff end</a> ]
    <p><li> 02/2020 - 07/2020, <strong>Teaching Assistant (TA) Tutor</strong> for postgraduate level course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=INFS7202"> INFS7202 Web Information System </a> at UQ</li></p>
    </li></p>

    
    


    <!-- <p class="w3-justify">
        Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
    </p> -->

        <!-- <h4><li>Adder Neural Networks</li></h4>
        <img style="width:96%;" src="images/AdderNet.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/AdderNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        </p>  -->
<!-- 
        <h4><li>GhostNet on MindSpore: SOTA Lightweight CV Networks</li></h4>
        <img style="width:96%;" src="images/GhostNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a>
        </p>
        <p class="w3-justify">
        The initial verison of GhostNet was accepted by CVPR 2020, which achieved SOTA performance on ImageNet: <span style="color:red">75.7%</span> top1 acc with only <span style="color:red">226M FLOPS</span>. In the current version, we release a series computer vision models (e.g. int8 quantization, detection, and larger networks) on <strong>MindsSpore 1.0</strong> and <strong>Mate 30 Pro (Kirin 990)</strong>.
        </p>  -->

<!--         <h4><li>AI on Ascend: Real-Time Video Style Transfer</li></h4>
        <img style="width:32%;" src="images/atlas200.png"> &nbsp&nbsp <img style="width:60%;" src="images/video.gif">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html">Huawei Developer Conference (HDC) 2020</a> | <a style="color: #447ec9" href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
        </p>
        <p class="w3-justify">
        This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
        </p>  
 -->
  </div>
  
  <!-- The Talks Section -->
<!--   <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/"><strong>VALSE</strong></a> Webinar.</li></p>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/"> Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/"> <strong>QbitAI</strong></a> using <a  href="https://www.bilibili.com/"><strong>bilibili</strong></a>.</li></p>
  </div> -->



 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Publication</h2>
 <!--      <p class="w3-left-align" style="line-height:200%">
        Ivan is interested in devleoping <strong>efficient models</strong> for computer vision (e.g. classification, detection, and super-resolution) using pruning, quantization, distilaltion, NAS, etc.
      </p> -->                                                        
                                                            
    <h4> Conference Papers:</h4>

    <ol>
      
      <p>
      <li><strong>Conditional Extreme Value Theory for Open Set Video Domain Adaptation</strong>
      <br>
      <strong>Zhuoxiao Chen</strong>, Yadan Luo, Mahsa Baktashmotlagh
      <br>
      <em>MMAsia</em> 2021 | <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3469877.3490600">paper</a>
      </p>

      <p>
      <li><strong>RoadAtlas: Intelligent Platform for Automated Road Defect Detection and Asset Management</strong>
      <br>
      <strong>Zhuoxiao Chen</strong>, Yiyun Zhang, Yadan Luo, Zijian Wang, Jinjiang Zhong, Anthony Southon
      <br>
      <em>MMAsia</em> 2021 | <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3469877.3493589">paper</a>
      </p>
    </ol>
                                                                                                                
   <h4> Submitted Papers:</h4>    
   <ol>
      <p>
      <li><strong>Source-Free Progressive Graph Learning for Open-Set Domain Adaptation</strong>
      <br>
      Yadan Luo, Zijian Wang, <strong>Zhuoxiao Chen</strong>, Zi Huang, Mahsa Baktashmotlagh
      <br>
      <em>Submitted to TPAMI</em> | <a style="color: #447ec9" href="https://arxiv.org/abs/2202.06174">paper</a>
      </p>
    </ol>
                                                                                                                
                                                                                                              

<!--       <p>
      <li><strong>HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens</strong>
      <br>
      Zhaohui Yang, <strong>Yunhe Wang</strong>, Xinghao Chen, Jianyuan Guo, Wei Zhang, 
      <br>
      Chao Xu, Chunjing Xu, Dacheng Tao, Chang Xu  
      <br>
      <em>CVPR</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2005.14446.pdf">paper</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.1/HourNAS-F_v1.0_cifar10">MindSpore code</a>
      </p>

      <p>
      <li><strong>Manifold Regularized Dynamic Network Pruning</strong>
      <br>
      Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Yiping Deng, Chao Xu, Dacheng Tao, Chang Xu
      <br>
      <em>CVPR</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2103.05861.pdf">paper</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.1/manidp_v1.0_cifar10">MindSpore code</a>
      </p>

      <p>
      <li><strong>Learning Student Networks in the Wild</strong>
      <br>
      Hanting Chen, Tianyu Guo, Chang Xu, Wenshuo Li, Chunjing Xu, Chao Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>CVPR</em> 2021 
      </p>
 -->
     
      
    
<!--       <p>
      <li><strong>Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts</strong>
      <br>
      Guilin Li*, Junlei Zhang*, <strong>Yunhe Wang</strong>, Chuanjian Liu, Matthias Tan, Yunfeng Lin,
      <br>
      Wei Zhang, Jiashi Feng, Tong Zhang
      <br>
      <em>NeurIPS</em> 2020 (* equal contribution) | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2020/file/657b96f0592803e25a4f07166fff289a-Paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/leoozy/JointRD_Neurips2020">code</a> 
      </p> -->

<!--       <p>
      <li><strong>Searching for Low-Bit Weights in Quantized Neural Networks</strong>
      <br>
      Zhaohui Yang, <strong>Yunhe Wang</strong>, Kai Han, Chunjing Xu, Chao Xu, Dacheng Tao, Chang Xu
      <br>
      <em>NeurIPS</em> 2020 | <a style="color: #447ec9" href="https://arxiv.org/abs/2009.08695.pdf">paper</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.0/VGG-Small-low-bit_cifar10">code</a> 
      </p>

      <p>
      <li><strong>SCOP: Scientific Control for Reliable Neural Network Pruning</strong>
      <br>
      Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Dacheng Tao, Chunjing Xu, Chao Xu, Chang Xu
      <br>
      <em>NeurIPS</em> 2020 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2010.10732">paper</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?2593/noah-cvlab/gpu/1.0/resnet-0.65x_v1.0_oxford_pets">code</a>
      </p>

      <p>
      <li><strong>Adapting Neural Architectures Between Domains</strong>
      <br>
      Yanxi Li, Zhaohui Yang, <strong>Yunhe Wang</strong>, Chang Xu
      <br>
      <em>NeurIPS</em> 2020 | <a style="color: #447ec9" href="https://papers.nips.cc/paper/2020/file/08f38e0434442128fab5ead6217ca759-Paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/liyxi/AdaptNAS">code</a>
      </p>

      <p>
      <li><strong>Discernible Image Compression</strong>
      <br>
      Zhaohui Yang, <strong>Yunhe Wang</strong>, Chang Xu, Peng Du, Chao Xu, Chunjing Xu, Qi Tian
      <br>
      <em>ACM MM</em> 2020 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2002.06810">paper</a>
      </p>
                    -->
      
      

     

<!--       <p>
      <li><strong>Frequency Domain Compact 3D Convolutional Neural Networks</strong>
      <br>
      Hanting Chen, <strong>Yunhe Wang</strong>, Han Shu, Yehui Tang, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu 
      <br>
      <em>CVPR</em> 2020 | <a style="color: #447ec9" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Frequency_Domain_Compact_3D_Convolutional_Neural_Networks_CVPR_2020_paper.pdf">paper</a>
      </p>

      <li><strong>GhostNet: More Features from Cheap Operations</strong>      
      <br>
      Kai Han, <strong>Yunhe Wang</strong>, Qi Tian, Jianyuan Guo, Chunjing Xu, Chang Xu
      <br>
      <em>CVPR</em> 2020 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Han_GhostNet_More_Features_From_Cheap_Operations_CVPR_2020_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/ghostnet">code</a> 
      </p>
      
      <p>
      <li><strong>Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks</strong>  
      <br>
      Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
      <br>
      <em>AAAI</em> 2020 | <a style="color: #447ec9" href="data/2020 AAAI dropblock.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/disout">code</a>
      </p>

      <p>
      <li><strong>DropNAS: Grouped Operation Dropout for Differentiable Architecture Search</strong>
      <br>
      Weijun Hong, Guilin Li, Weinan Zhang, Ruiming Tang, <strong>Yunhe Wang</strong>, Zhenguo Li, Yong Yu
      <br>
      <em>IJCAI</em> 2020 | <a style="color: #447ec9" href="https://www.ijcai.org/Proceedings/2020/0322.pdf">paper</a> 
      </p> -->

<!--       
      <p>
      <li><strong>Autoencoder Inspired Unsupervised Feature Selection</strong>
      <br>
      Kai Han, <strong>Yunhe Wang</strong>, Chao Zhang, Chao Li, Chao Xu 
      <br>
      <em>ICASSP</em> 2018 | <a style="color: #447ec9" href="data/2018 ICASSP Feature Selector.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/NoahLuffy/AEFS">code</a> 
      </p>

      <p>
      <li><strong>Adversarial Learning of Portable Student Networks</strong>
      <br>
      <strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao 
      <br>
      <em>AAAI</em> 2018 | <a style="color: #447ec9" href="data/2018 AAAI Adversarial Distillation.pdf">paper</a> 
      </p>

      <p>
      <li><strong>Beyond Filters: Compact Feature Map for Portable Deep Model</strong>
      <br>
      <strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao 
      <br>
      <em>ICML</em> 2017 | <a style="color: #447ec9" href="data/2017 ICML Beyond Filters.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/YunheWang/RedCNN">code</a> | <a style="color: #447ec9" href="http://proceedings.mlr.press/v70/wang17m/wang17m-supp.zip">supplement</a>
      </p> -->

     
<!--
      </ol>

       <h4> Journal Papers:</h4>

      <ol>

      <p>
      <li><strong>Adversarial Recurrent Time Series Imputation</strong>
      <br>
      Shuo Yang, Minjing Dong, <strong>Yunhe Wang</strong>, Chang Xu
      <br>
      <em>IEEE TNNLS</em> 2020 |<a style="color: #447ec9" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9158560">paper</a>
      </p> -->
  
<!--       <p>
      <li><strong>Learning Student Networks via Feature Embedding</strong>
      <br>
      Hanting Chen, <strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
      <br>
      <em>IEEE TNNLS</em> 2020 | <a style="color: #447ec9" href="https://arxiv.org/pdf/1812.06597">paper</a>
      </p>

      <p>
      <li><strong>Packing Convolutional Neural Networks in the Frequency Domain</strong>
      <br>
      <strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
      <br>
      <em>IEEE TPAMI</em> 2018 | <a style="color: #447ec9" href="data/2018 PAMI CNNpack.pdf">paper</a>
      </p>

      <p>
      <li><strong>DCT Regularized Extreme Visual Recovery</strong>
      <br>
      <strong>Yunhe Wang</strong>, Chang Xu, Shan You, Chao Xu, Dacheng Tao
      <br>
      <em>IEEE TIP</em> 2017 | <a style="color: #447ec9" href="data/2017 TIP DCT norm.pdf">paper</a> 
      </p>

      <p>
      <li><strong>DCT Inspired Feature Transform for Image Retrieval and Reconstruction</strong>
      <br>
      <strong>Yunhe Wang</strong>, Miaojing Shi, Shan You, Chao Xu
      <br>
      <em>IEEE TIP</em> 2016 | <a style="color: #447ec9" href="data/2016 TIP DCT feature.pdf">paper</a>
      </p> -->

      </ol>

    </p>
  </div> 

<!-- The Services Section -->
<!--   <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Area Chair of <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div> -->
  
  

  <!-- The Awards Section -->
  <div class="w3-container w3-light-grey  w3-padding-32" id="award" style="margin-bottom: 10px">
    <h2>Awards</h2>
    <p><li> 12/2021, <strong><a href="https://scholarships.uq.edu.au/scholarship/graduate-school-scholarships-uqgss-–-includes-rtp">Graduate School Scholarships (UQGSS)</a></strong>, these scholarships cover a living allowance stipend and tuition fee expenses</p>                                                                                                
    <p><li> 07/2021, <strong>Certificate of Recognition</strong>, in recognition of Ivan’s dedication, enthusiasm and commitment to excellence in research</p>     
    <p><li> 12/2020, <strong>UQ Excellence Scholarship for International Students</strong>, this scholarship provided by UQ covers 20% of your tuition fees per year, for GPA top 5% students only</p>  
    <p><li> Semester 1 & 2 in 2020, Semester 1 & 2 in 2021, <strong>Dean’s Commendation for Academic Excellence</strong>, The Faculty of Engineering, Architecture and Information Technology, has determined that students who demonstrate excellence in academic performance should receive acknowledgement of the achievement</p>           
<!--     <p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
    <p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship</a></p>
    <p><li> 2017, President's PhD Scholarship, Peking University</p>
    <p><li> 2017, National Scholarship for Graduate Students</p> -->
    <!-- <p><li> 2016, National Scholarship for Graduate Students</p> -->
  </div>  
  
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=H-3L_AFM70uBV-0qYaVRTm8A59eEAl1XLqMprr6uHZM&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>                                               
  <div class=" w3-center w3-padding-24">
    

    Welcome to use this website's <a href="https://github.com/zhuoxiao-chen/zhuoxiao-chen.github.io">source code</a>, just add a link back to here. <a href="https://zhuoxiao-chen.github.io">&#10025;</a></br>

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
