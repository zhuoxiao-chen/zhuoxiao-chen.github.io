<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  
  <title>Zhuoxiao (Ivan) Chen's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="baidu-site-verification" content="code-icRL3fjRSM" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Mr Chen is currently a research assistant at The University of Queensland.">
  <meta name="keywords" content="Zhuoxiao Chen, 陈卓潇, Ivan Chen, Zhuoxiao (Ivan) Chen, Zhuoxiao, Chen, Deep Learning, Domain Adaptation, UQ, University of Queensland, The University of Queensland, Computer, Vision">
  <meta name="author" content="Zhuoxiao Chen" />

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro&display=swap" rel="stylesheet">


  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=LXGW+WenKai+Mono+TC:wght@300;400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Trebuchet MS", Tahoma, sans-serif; }
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Trebuchet MS", Tahoma, sans-serif; }
  </style>

  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:100%">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:200px" id="mySidebar">

  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#publications" class="w3-bar-item w3-button">Publication</a>
    <a href="#research_services" class="w3-bar-item w3-button">Research Services</a>
    <a href="#teaching" class="w3-bar-item w3-button">Teaching</a>
    <a href="#education" class="w3-bar-item w3-button">Education</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
    <a href="#other_experience" class="w3-bar-item w3-button">Others</a>

    <!-- <a href="#talks" class="w3-bar-item w3-button">Talks</a> -->
    <!-- <a href="#service" class="w3-bar-item w3-button">Services</a> -->
    <a href="https://github.com/zhuoxiao-chen/paper-notes" class="w3-bar-item w3-button">Paper Notes</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:200px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32 w3-light-grey" id="home" 
         style="display: flex;align-items: center;justify-content: center;flex-wrap: wrap;flex-direction: row;align-content: center;">

      <img style="width: 25%;min-width: 200px;max-width: 240px; border-radius: 10px;" src="images/ivan2.jpg">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
      <div style="padding: 0 3%;">
      <div style="
    display: flex;
    justify-content: center;
    flex-direction: row;
    flex-wrap: wrap;
    align-content: center;"><h1>Zhuoxiao (Ivan) Chen</h1> <h3 class="lxgw-wenkai-mono-tc-bold">[陈卓潇]</h3></div>

      <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px">
  I was an AI Scientist Intern in 2025 at Oracle Health and AI (OHAI), supervised by <a href="https://au.linkedin.com/in/liyuanfang">Dr Yuan-Fang Li</a>, 
  where I developed large vision–language models tailored to healthcare data. 
  I received my PhD in 2026 from <a href="https://www.uq.edu.au/">The University of Queensland (UQ)</a>, Australia, 
  under the supervision of <a href="https://luoyadan.github.io/">Dr Yadan Luo</a>, 
  <a href="https://staff.itee.uq.edu.au/huang/">Prof Helen Huang</a>, 
  and <a href="https://researchers.uq.edu.au/researcher/23393">Dr Mahsa Baktashmotlagh</a>. 
  My research focused on improving model generalization for 3D scene understanding. 
  I received my Bachelor of Computer Science with First Class Honours from UQ in 2021, and 
  had the honor of serving as <a href="https://my.uq.edu.au/graduation/graduation-speeches">Valedictorian</a> 
  at the December 2021 graduation ceremony.
        </p>
      <p>
      I’m actively seeking <strong>full-time roles</strong> in
      <strong>AI / ML / DL / 3D Vision / LLM / VLM</strong>!
      </p>
        Email: zhuoxiao [dot] chen [at] uq [dot] edu [dot] au
        <p class="w3-center">
          <a href="https://scholar.google.com/citations?user=t3cg17IAAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href=" https://github.com/zhuoxiao-chen">GitHub</a> &nbsp/&nbsp
          <a href="https://dblp.org/pid/301/7822.html"> DBLP </a> &nbsp/&nbsp
          <a href="https://www.instagram.com/ivan_chen_uq/"> IG </a>
        </p>
        </tbody></table>
        </div>

  </div>

<!-- The News Section -->
  <!-- <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
    
    <p><li> 01/2023, one (spotlight) paper about active learning for 3D object detection has been accepted by <a href="https://iclr.cc/">ICLR 2023</a> </li></p>
    <p><li> 02/2022, I am now a teaching assistant (TA) tutor for undergraduate/postgraduate courses at UQ </li></p>
          
    <p><li> 12/2021, I was selected as the <a href="https://my.uq.edu.au/graduation/graduation-speeches">Valedictorian</a> to present a speech in the graduation ceremony of the Faculty of 
Engineering, Architecture and Information Technology</li></p>
      
         
    <p><li> 10/2021, two papers have been accepted by <a href="https://www.acmmmasia.org/">ACM MMAsia</a></li></p>


  </div> -->

 <!-- The Publications Section -->

 <div class="w3-container w3-padding-32 " id="publications">
  <h2 style="text-align: center;">Publication</h2>


     <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/orapo.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation</strong><br>
      <strong>Zhuoxiao Chen</strong>, Hongyang Yu, Ying Xu, Yadan Luo, Long Duong, Yuan-Fang Li <br>
      <em>CVPR</em> 2026 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://ieeexplore.ieee.org/abstract/document/11163594/">[paper]</a> 
      <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2310.10391">[arXiv]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/Luoyadan/CRB-active-3Ddet/tree/Open-CRB">[code]</a>
      <br> 
      In this paper, we propose Oracle-educated GRPO (OraPO) with a FactScore-based reward (FactS) to tackle the radiology report generation (RRG task) under constrained budgets. 
      OraPO enables single-stage, RL-only training by converting failed GRPO explorations on rare or difficult studies into direct preference supervision via a 
      lightweight oracle step. FactS grounds learning in diagnostic evidence by extracting atomic clinical facts and checking entailment against ground-truth labels, 
      yielding dense, interpretable sentence-level rewards. 
      Together, OraPO and FactS create a compact and powerful framework that significantly improves learning efficiency on clinically challenging cases, 
      setting the new SOTA performance on the CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training data using a small base VLM on modest hardware.
    </p>
      </div>
  </div>
   


  <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/open-crb.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>Open-CRB: Active Learning for 3D Object Detection from Open World</strong><br>
      <strong>Zhuoxiao Chen</strong>, Yadan Luo, Zixin Wang, Zijian Wang, Zi Huang<br>
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> 2025 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://ieeexplore.ieee.org/abstract/document/11163594/">[paper]</a> 
      <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2310.10391">[arXiv]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/Luoyadan/CRB-active-3Ddet/tree/Open-CRB">[code]</a>
      <br> This paper investigates a more practical and challenging research task: 
      Open World Active Learning for 3D Object Detection (OWAL-3D), aimed at acquiring informative point clouds with new concepts. 
      We propose a simple yet effective strategy called Open Label Conciseness (OLC), 
      which mines novel 3D objects with minimal annotation costs. Our empirical results show that OLC successfully adapts 
      the 3D detection model to the open world scenario with just a single round of selection. 
      Any generic AL policy can then be integrated with the proposed OLC to efficiently address the OWAL-3D problem.
    </p>
      </div>
  </div>


     <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/codemerge.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving</strong><br>
      Huitong Yang, <strong>Zhuoxiao Chen</strong>, Fengyi Zhang, Zi Huang, Yadan Luo<br>
      <em>NeurIPS</em> 2025 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2505.16524">[arXiv]</a> 
      <a style="color: #447ec9; text-decoration: none" href="">[code]</a>

      <br>  Maintaining robust 3D perception under dynamic and unpredictable test-time conditions remains a critical challenge for autonomous driving systems.
      In this paper, we introduce CodeMerge, a lightweight and scalable model merging framework that bypasses these limitations by operating in a compact latent space. 
      Instead of loading full models, CodeMerge represents each checkpoint with a low-dimensional fingerprint derived from the source model's penultimate features and constructs a key-value codebook. 
      We compute merging coefficients using ridge leverage scores on these fingerprints, enabling efficient model composition without compromising adaptation quality. 
    </p>
      </div>
  </div>
   


  <div class="w3-container w3-center " id="home" 
  style="display: flex;
  align-items: center;
  justify-content: center;
  flex-wrap: wrap;
  flex-direction: row;
  align-content: center;padding: 8px 0px;">

<img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/mos.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
<div style="padding: 0 2%;">

<p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
 <strong>MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object Detection</strong><br>
 <strong>Zhuoxiao Chen</strong>, Junjie Meng, Mahsa Baktashmotlagh, Yonggang Zhang, Zi Huang, Yadan Luo <br>
 <em>ICLR</em> 2025 <strong>(Oral)</strong><br>
 <a style="color: #447ec9;  text-decoration: none" href="https://openreview.net/forum?id=Y6aHdDNQYD">[OpenReview]</a> 
 <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2406.14878">[arXiv]</a> 
 <a style="color: #447ec9; text-decoration: none" href="https://github.com/zhuoxiao-chen/MOS">[code]</a>
 <br> LiDAR-based 3D object detection is crucial for various applications but often experiences performance degradation in real-world deployments due to 
 domain shifts. While most studies focus on cross-dataset shifts, such as changes 
 in environments and object geometries, practical corruptions from sensor variations and 
 weather conditions remain underexplored. In this work, we propose a novel online test-time 
 adaptation framework for 3D detectors that effectively tackles these shifts, 
 including a challenging cross-corruption scenario where cross-dataset shifts and 
 corruptions co-occur. By leveraging long-term knowledge from previous test batches, 
 our approach mitigates catastrophic forgetting and adapts effectively to diverse shifts.
</p>
 </div>
</div>

   

  <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/dipex.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>DiPEx: Dispersing Prompt Expansion for Class-Agnostic Object Detection</strong><br>
      Jia Syuen Lim*, <strong>Zhuoxiao Chen*</strong>, Mahsa Baktashmotlagh, Zhi Chen, Xin Yu, Zi Huang, Yadan Luo <br>
      <em>NeurIPS</em> 2024 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://openreview.net/forum?id=NDs9Ejz4Pe">[OpenReview]</a> 
      <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2406.14924">[arXiv]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/jason-lim26/DiPEx">[code]</a>
      <br> Class-agnostic object detection (OD) can be a cornerstone or a bottleneck for many downstream vision tasks. 
      Despite considerable advancements in bottom-up and multi-object discovery methods that leverage basic visual cues to 
      identify salient objects, consistently achieving a high recall rate remains difficult due to the diversity of object types and 
      their contextual complexity. 
      In this work, we investigate using vision-language models (VLMs) to enhance object detection via a self-supervised prompt learning strategy. 
    </p>
      </div>
  </div>





  <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/DPO.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection</strong><br>
      <strong>Zhuoxiao Chen*</strong>, Zixin Wang*, Sen Wang, Zi Huang, Yadan Luo <br>
      <em>MM</em> 2024 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://dl.acm.org/doi/10.1145/3664647.3681040">[paper]</a> 
      <a style="color: #447ec9;  text-decoration: none" href="https://openreview.net/forum?id=eoaw2A8X4J">[OpenReview]</a> 
      <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2406.13891">[arXiv]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/Jo-wang/DPO">[code]</a>
      <br> We propose dual-perturbation optimization (DPO) for Test-Time Adaptation for 3D Object Detection (TTA-3OD). 
      We minimize the sharpness to cultivate a flat loss landscape to ensure model resiliency to minor data variations, 
      thereby enhancing the generalization of the adaptation process. 
      To fully capture the inherent variability of the test point clouds, 
      we further introduce adversarial perturbation to the input BEV features to better simulate the noisy test environment. 
      As the dual perturbation strategy relies on trustworthy supervision signals, 
      we utilize a reliable Hungarian matcher to filter out pseudo-labels sensitive to perturbations. 
      Additionally, we introduce early Hungarian cutoff to avoid error accumulation from incorrect pseudo-labels by halting the adaptation process.
    </p>
      </div>
  </div>

  <div class="w3-container w3-center " id="home" 
  style="display: flex;
  align-items: center;
  justify-content: center;
  flex-wrap: wrap;
  flex-direction: row;
  align-content: center;padding: 8px 0px;">

<img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/ijcv.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
<div style="padding: 0 2%;">

<p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
 <strong>  In Search of Lost Online Test-Time Adaptation: A Survey</strong><br>

 Zixin Wang, Yadan Luo, Liang Zheng,  <strong>Zhuoxiao Chen</strong>, Sen Wang, Zi Huang <br>
 <em>IJCV</em> 2024 <br>
 <a style="color: #447ec9;  text-decoration: none" href="https://link.springer.com/article/10.1007/s11263-024-02213-5">[paper]</a>
 <a style="color: #447ec9;  text-decoration: none" href="https://arxiv.org/abs/2310.20199">[arXiv]</a> 
 <a style="color: #447ec9; text-decoration: none" href="https://github.com/Jo-wang/OTTA_ViT_survey">[code]</a>
 <br> This article presents a comprehensive survey of online test-time adaptation (OTTA), 
 focusing on effectively adapting machine learning models to distributionally different target data upon batch arrival. 
 Despite the recent proliferation of OTTA methods, conclusions from previous studies are inconsistent due to ambiguous settings, 
 outdated backbones, and inconsistent hyperparameter tuning, which obscure core challenges and hinder reproducibility. 
</p>
 </div>
</div>




     <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/REDB.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling</strong><br>
      <strong>Zhuoxiao Chen</strong>, Yadan Luo, Zi Huang, Zheng Wang, Mahsa Baktashmotlagh <br>
      <em>ICCV</em> 2023 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.html">[paper]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet">[code]</a>
      <a style="color: #447ec9; text-decoration: none" href="https://www.youtube.com/watch?v=NDR4unATTiw">[video]</a>
      <br>
     Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. 
      While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, 
      due to the co-existence of low-quality pseudo labels and class imbalance issues. 
      In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. 
      Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally 
      different target domain.
    </p>
      </div>
  </div>

     <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/kecor.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection</strong><br>
      Yadan Luo, <strong>Zhuoxiao Chen</strong>, Zhen Fang, Zheng Zhang, Zi Huang, Mahsa Baktashmotlagh <br>
      <em>ICCV</em> 2023 <br>
      <a style="color: #447ec9;  text-decoration: none" href="https://openaccess.thecvf.com/content/ICCV2023/html/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.html">[paper]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/Luoyadan/KECOR-active-3Ddet">[code]</a>
      <br>
Active learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. 
      Although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high aleatoric and/or epistemic uncertainty, 
      leading to the selection of more instances for labeling and reduced computational efficiency. 
      In this paper, we resort to a novel kernel coding rate maximization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels 
      through the lens of information theory. 
    </p>
      </div>
  </div>


   

  <div class="w3-container w3-center " id="home" 
       style="display: flex;
       align-items: center;
       justify-content: center;
       flex-wrap: wrap;
       flex-direction: row;
       align-content: center;padding: 8px 0px;">

    <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/crb.png">
<!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
    <div style="padding: 0 2%;">
 
    <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
      <strong>Exploring Active 3D Object Detection from a Generalization Perspective</strong><br>
      Yadan Luo*, <strong>Zhuoxiao Chen*</strong>, Zijian Wang, Xin Yu, Zi Huang, Mahsa Baktashmotlagh <br>
      <em>ICLR </em> 2023 <strong>(Spotlight)</strong><br>
      <a style="color: #447ec9;  text-decoration: none" href="https://openreview.net/forum?id=2RwXVje1rAh">[OpenReview]</a> 
      <a style="color: #447ec9; text-decoration: none" href="https://github.com/Luoyadan/CRB-active-3Ddet">[code]</a>
      <br>
      To alleviate the high annotation cost in LiDAR-based 3D object detection, 
      active learning is a promising solution that learns to select only a small portion of unlabeled data to annotate, 
      without compromising model performance. We jointly investigate three novel criteria in our framework CRB for point cloud acquisition - label conciseness, feature representativeness and 
      geometric balance, which hierarchically filters out the point clouds of redundant 3D bounding box labels, latent features and geometric characteristics (e.g., point cloud density) 
      from the unlabeled sample pool and greedily selects informative ones with fewer objects to annotate. 
    </p>
      </div>
  </div>


  <div class="w3-container w3-center" id="home" 
  style="display: flex;
  align-items: center;
  justify-content: center;
  flex-wrap: wrap;
  flex-direction: row;
  align-content: center;padding: 8px 0px;">
  
  <img style="width: 200px; border-radius: 10px; border-radius: 10px;" src="images/PGL.png">
  <!--       <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-left:auto;max-width:600px"> </p> -->
  <div style="padding: 0 2%;">
  
  <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px;margin-top:0px">
  <strong>Source-Free Progressive Graph Learning for Open-Set Domain Adaptation</strong><br>
  Yadan Luo, Zijian Wang, <strong>Zhuoxiao Chen</strong>, Zi Huang, Mahsa Baktashmotlagh <br>
  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> <br> 
  <a style="color: #447ec9;  text-decoration: none" href="https://ieeexplore.ieee.org/abstract/document/10107906">[paper]</a>
  <a style="color: #447ec9; text-decoration: none" href="https://github.com/Luoyadan/SF-PGL">[code]</a>
  <br>
  We propose a Progressive Graph Learning (PGL) framework that decomposes the target hypothesis space into the shared and unknown subspaces, and then progressively pseudo-labels the most confident known samples from the target domain for
hypothesis adaptation. 
  </p>
  </div>
  </div>

  
  </div> 


<!-- The Research Services Section -->
<div class="w3-container w3-light-grey w3-padding-32" id="research_services">

  <h2>Research Services</h2>
  I serve as a reviewer for the following top conferences:   
  <p><li> <strong> ACL ARR </strong> in 2025
  <p><li> <strong> ICML </strong> in 2025
  <p><li> <strong> ICLR </strong> in 2025
  <p><li> <strong> ICCV </strong> in 2025
  <p><li> <strong> WWW </strong> in 2025
  <p><li> <strong> NeurIPS </strong> in 2024, 2025
  <p><li> <strong> CVPR </strong> in 2024, 2025
  <p><li> <strong> ECCV </strong> in 2024
  <p><li> <strong> ACM MM </strong> in 2023, 2024, 2025
  <br><br>
  and top journals: 
  <p><li> <strong> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </strong> in 2024
  <p><li> <strong> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </strong> in 2024
  <p><li> <strong> IEEE Transactions on Multimedia (TMM) </strong> in 2024

</div>

  <!-- The Industry Section -->
<div class="w3-container  w3-padding-32" id="teaching">

  <h2>Industry Experience</h2>
  <p><li>06/2025-12/2025<strong> AI Scientist Intern</strong> at Oracle </li></p>
</div>

<!-- The Teaching Section -->
<div class="w3-container  w3-light-grey w3-padding-32" id="teaching">

  <h2>Teaching Experience</h2>
  <p><li>2022, 2023, 2024, 2025, <strong>Head of Tutor</strong> for postgraduate level course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=INFS4205">INFS7205 Advanced Techniques for High Dimensional Data</a></li></p>
  <p><li> 2022, <strong>Teaching Assistant (TA) Tutor</strong> for master thesis <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DATA7901">Data Science Capstone Project (DATA7901)</a> and <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DATA7902">Data Science Capstone Project (DATA7902)</a></li></p>
  <p><li> 2022, 2024, <strong>Learning Designer</strong> for 2nd year university computer science courses</li></p>
  <p><li>2021, <strong>Teaching Assistant (TA) Tutor</strong> for postgraduate level course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=INFS7202">INFS7202 Web Information Systems</a></li></p>
</div>

<!-- The Education Section -->
 <div class="w3-container  w3-padding-32" id="education">
   <h2>Education</h2>
    <p><li> 01/2022 - 12/2025, <strong>Doctor of Philosophy (PhD) </strong>, The University of Queensland
    <p><li> 02/2018 - 12/2021, <strong>Bachelor of Computer Science (First Class Honours) </strong>, The University of Queensland, <em><strong>GPA Rank 1st</strong></em> </li></p>
</div>


  <!-- The Awards Section -->
  <div class="w3-container  w3-light-grey w3-padding-32" id="award" style="margin-bottom: 10px">
    <h2>Awards</h2> 
     <p><li> 12/2021, <strong><a href="https://my.uq.edu.au/graduation/graduation-speeches">Valedictorian</a></strong>, I was selected as the <a href="https://my.uq.edu.au/graduation/graduation-speeches">Valedictorian</a> to present a speech in the graduation ceremony of the Faculty of 
Engineering, Architecture and Information Technology </li></p>
                                                                                                           
    <p><li> 12/2021, <strong><a href="https://scholarships.uq.edu.au/scholarship/graduate-school-scholarships-uqgss-–-includes-rtp">Graduate School Scholarships (UQGSS)</a></strong>, these scholarships cover a living allowance stipend and tuition fee expenses</p>                                                                                                
    <!-- <p><li> 07/2021, <strong>Certificate of Recognition</strong>, in recognition of Ivan’s dedication, enthusiasm and commitment to excellence in research</p>      -->
    <p><li> 12/2020, <strong>UQ Excellence Scholarship for International Students</strong>, this scholarship provided by UQ covers 20% of your tuition fees per year, for GPA top 5% students only</p>  
    <p><li> Semester 1 & 2 in 2020, Semester 1 & 2 in 2021, <strong>Dean’s Commendation for Academic Excellence</strong>, The Faculty of Engineering, Architecture and Information Technology, has determined that students who demonstrate excellence in academic performance should receive acknowledgement of the achievement</p>           
<!--     <p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
    <p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship</a></p>
    <p><li> 2017, President's PhD Scholarship, Peking University</p>
    <p><li> 2017, National Scholarship for Graduate Students</p> -->
    <!-- <p><li> 2016, National Scholarship for Graduate Students</p> -->
  </div>  



<!-- The Experience Section -->
  <div class="w3-container  w3-padding-32" id="other_experience">
    <h2>Other Experience</h2>
    <p><li> 07/2021 - now, <strong>Research Assistant (RA) </strong> at ITEE, UQ</li></p>
    <p><li> 08/2021 - 09/2021, <strong>Software Engineer</strong> for collaborative project (ITEE, UQ and <a href="https://www.logan.qld.gov.au/">Logon City Council, Australia</a>) on intelligent platform for automated road defect detection and asset management [ <a style="color: #447ec9" href="https://arxiv.org/abs/2109.00522">project</a> ]</li></p> 
    <!-- <p><li> 06/2021 - 07/2021, <strong>Winter Research Scholar</strong> of <a href="https://scholarships.uq.edu.au/scholarship/winter-research-program">Winter Research Program</a> at UQ</li></p> -->
    <p><li> 03/2021, <strong>Web Developer </strong> for <a href="https://mmasia2021.uqcloud.net/"> ACM Multimedia Asia 2021 Official Website </a> </li></p>
    <!-- <p><li> 07/2020 - 11/2020, <strong>Team Leader</strong> of software development team - Dodo Lab in course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=DECO3801">deco3801</a> at UQ. The developed product is CovidStopper
    	[ <a style="color: #447ec9" href="https://drive.google.com/file/d/1OIK1LD6SeN1Td5xjFoqbifmPVMy6L7Ie/view?usp=sharing">commercial end</a> ][
    	<a style="color: #447ec9" href="https://drive.google.com/file/d/1Wx4ZQ3okz9F56wITXvNiyPvjty1teB0r/view?usp=sharing">general end</a> ][
    	<a style="color: #447ec9" href="https://drive.google.com/file/d/1QxxJUis61TRrZKBzAJ10uvrCgr1lPt-z/view?usp=sharing">lab staff end</a> ]
    <p><li> 02/2020 - 07/2020, <strong>Teaching Assistant (TA) Tutor</strong> for postgraduate level course <a href="https://my.uq.edu.au/programs-courses/course.html?course_code=INFS7202"> INFS7202 Web Information System </a> at UQ</li></p>
    </li></p> -->

  </div>
  
  <!-- The Talks Section -->
<!--   <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/"><strong>VALSE</strong></a> Webinar.</li></p>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/"> Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/"> <strong>QbitAI</strong></a> using <a  href="https://www.bilibili.com/"><strong>bilibili</strong></a>.</li></p>
  </div> -->


<!-- The Services Section -->
<!--   <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Area Chair of <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div> -->
  
  


  
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=H-3L_AFM70uBV-0qYaVRTm8A59eEAl1XLqMprr6uHZM&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>                                               
  <div class=" w3-center w3-padding-24">
    

    Welcome to use this website's <a href="https://github.com/zhuoxiao-chen/zhuoxiao-chen.github.io">source code</a>, just add a link back to here. <a href="https://zhuoxiao-chen.github.io">&#10025;</a></br>

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
